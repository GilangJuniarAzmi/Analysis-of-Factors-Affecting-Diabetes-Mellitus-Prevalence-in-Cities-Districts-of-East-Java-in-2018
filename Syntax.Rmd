---
title: "Analysis of Factors Affecting Diabetes Prevalence in Cities/Districts of East Java in 2018"
output: html_notebook
author: Gilang Juniar Azmi
team: Analisis Regresi Minor_K2
team members:
  1. Gilang Juniar Azmi
  2. Putri Qoonitah Dewi
  3. Siti Yuditha Cahaya Anugerah
---

```{r}
diabetes <- read.table(header = T, text = "
y	x1	x2	x3	x4	x5	x6	x7	x8	x9	x10	x11 x12
1.04	39.6	80.86	23.62	19.81	74.54	1.09	9.06	84.82	15.32	2.7	8.66	1.39
1.75	24.65	73.25	24.13	26.37	68.43	0.7	9.21	83.91	16.18	4.23	6.82	3.77
1.34	17.42	60.41	23.08	21.24	54.86	0.8	9.69	87.72	16.49	4.05	9.08	4.12
1.5	31.78	47.08	18.74	24.58	36.23	0.96	10.3	85.56	18.4	3.46	6.93	2.53
2.01	20.16	57.53	22.89	17.01	47.09	0.98	9.99	82.65	22.61	7.15	9.05	3.38
1.98	40.33	64.68	23.94	18.64	37.89	1.04	10.16	86.12	25.02	3.47	7.08	4.15
1.4	32.9	64.55	27.05	20.16	48.29	1.83	12.13	84.78	23.53	7.02	10.14	3.15
1.87	32.7	65.01	28.09	24.35	61.44	1.58	10.23	87.9	22.56	10.92	9.23	2.46
1.45	28.92	56.02	27.88	37.7	50.69	1.91	10.88	88.66	22.65	8.24	7.91	4.01
1.55	24.7	52.1	25.71	21.68	38.57	2.07	11.46	84.27	24.77	8.2	8.64	3.59
1.24	33.45	62.75	28.11	29.64	52.62	1.58	12.83	91.6	16.68	7.23	8.89	3.84
2.19	30.75	54.66	28.48	23.65	58.55	2.59	15.07	85.7	19.54	15.1	8.57	1.85
1.66	35.74	67.17	29.92	21.06	57.24	2	12.08	89.88	21.57	15.72	9.35	4
1.71	50.69	66.76	23.13	27.92	42.06	1.74	13.36	84.64	23.95	9.65	6.18	5.94
3.47	40.18	54.74	20.46	42.89	46.17	1.63	11.7	74.11	27.99	9.68	7.52	4.62
2.25	39.11	57.08	23.54	26.25	61.17	0.87	10.97	89.23	25.2	5.84	8.69	4.21
2.76	37.96	70.17	24.59	17.56	39.25	1.59	10.73	84.68	24.5	7.07	8.98	4.56
1.95	30.88	60.11	22.57	25.47	56.39	2.88	12.04	84.93	21.45	4.14	7.83	2.6
2.3	33.44	69.81	22.66	18.99	75.2	0.83	10.03	82.51	20.47	2.99	8.02	3.71
1.96	32.57	72.33	22.88	16.41	66.32	1.15	9.52	79.72	22.15	3.68	7.46	3.82
2.51	32.04	65.92	22.49	16.74	73.13	1.05	10	85.17	17.76	4.26	8.19	3.75
1.72	29.98	53.64	26.29	22.67	69.52	1.95	11.54	82.92	19.65	3.26	7.85	4.11
1.24	24.24	50.65	23.99	16.17	51.42	1.58	11.3	87.57	15.12	3.77	6.22	2.76
1.86	27.75	54.36	22.86	25.4	46.69	0.84	11.14	84.89	20.42	7.89	8.16	3.1
3.44	35.74	58.34	21.71	23.18	48.16	1.17	11.8	77	26.92	11.49	9.08	5.71
1.28	20	24.03	19.62	40.63	18.46	1.22	17.7	88.81	16.51	22.69	6.56	5.09
0.99	14.55	26.78	19.82	28.1	28.22	1	15.97	92.71	16.07	16.06	5.8	2.38
1.08	26.9	40.2	21.3	33.68	33.91	0.88	16.43	92.08	15.72	25.21	4.76	2.88
0.75	17.2	34.51	28.25	29.86	12.68	0.58	16.78	92.53	16.48	9.9	4.24	1.75
2.68	32.77	58.64	22.74	29.51	35.41	0.72	11.71	80.88	24.57	4.81	8.11	3.56
2.57	32.3	57.02	18.88	28.78	29.62	0.86	11.42	70.54	31.93	3.92	7.86	3.98
2.29	30.05	58.82	23.31	31.55	55.73	1.35	12.38	74.61	29.17	7.49	10.06	6.65
3.4	37.66	62.72	23.42	33.07	70.53	1.65	12.71	80.74	30.76	18.09	10.89	3.56
2.82	35.15	60.86	20.37	43.87	47.35	1.45	14.33	81.04	29.73	16.15	7.41	4.5
3.83	24.07	53.81	22.1	37.03	57.74	1.41	10.84	69.19	32.13	8.91	9.33	2.44
4.22	28.82	57.95	20.02	22.89	63.05	0.85	10.48	67.97	29.81	6.27	7.82	3.8
3.48	30.86	53.21	20.69	33.22	46.35	1.33	12.58	72.91	28	12.23	8.72	6.01
1.91	27.7	52.74	23.24	16.46	46.13	0.77	11.85	81.79	26.68	3.32	7.46	3.07")

```
```{r}
# MODEL REGRESI
# Uji hipotesis simultan
model<-lm(y ~ ., data = diabetes)
anova(model)
summary(model)
```
```{r}
# uji hipotesis parsial
reg.X1 <- lm(y ~ x2+x3+x4+x5+x6+x7+x8+x9+x10+x11+x12, data = diabetes)
anova(reg.X1, model)
summary(reg.X1)

reg.X2 <- lm(y ~ x1+x3+x4+x5+x6+x7+x8+x9+x10+x11+x12, data = diabetes)
anova(reg.X2, model)
summary(reg.X2)

reg.X3 <- lm(y ~ x1+x2+x4+x5+x6+x7+x8+x9+x10+x11+x12, data = diabetes)
anova(reg.X3, model)
summary(reg.X3)

reg.X4 <- lm(y ~ x1+x2+x3+x5+x6+x7+x8+x9+x10+x11+x12, data = diabetes)
anova(reg.X4, model)
summary(reg.X4)

reg.X5 <- lm(y ~ x1+x2+x3+x4+x6+x7+x8+x9+x10+x11+x12, data = diabetes)
anova(reg.X5, model)
summary(reg.X5)

reg.X6 <- lm(y ~ x1+x2+x3+x4+x5+x7+x8+x9+x10+x11+x12, data = diabetes)
anova(reg.X6, model)
summary(reg.X6)

reg.X7 <- lm(y ~ x1+x2+x3+x4+x5+x6+x8+x9+x10+x11+x12, data = diabetes)
anova(reg.X7, model)
summary(reg.X7)

reg.X8 <- lm(y ~ x1+x2+x3+x4+x5+x6+x7+x9+x10+x11+x12, data = diabetes)
anova(reg.X8, model)
summary(reg.X8)

reg.X9 <- lm(y ~ x1+x2+x3+x4+x5+x6+x7+x8+x10+x11+x12, data = diabetes)
anova(reg.X9, model)
summary(reg.X9)

reg.X10 <- lm(y ~ x1+x2+x3+x4+x5+x6+x7+x8+x9+x11+x12, data = diabetes)
anova(reg.X10, model)
summary(reg.X10)

reg.X11 <- lm(y ~ x1+x2+x3+x4+x5+x6+x7+x8+x9+x10+x12, data = diabetes)
anova(reg.X11, model)
summary(reg.X11)

reg.X12 <- lm(y ~ x1+x2+x3+x4+x5+x6+x7+x8+x9+x10+x11, data = diabetes)
anova(reg.X12, model)
summary(reg.X12)
```

```{r}
# == Matriks Korelasi == #
library(corrplot)
corrplot(cor(diabetes[,c(1:13)]), method="number", type="upper", sig.level=0.05)
korelasi = cor(diabetes)
korelasi
```

```{r}
# == Scatter Plot Antarpeubah == #
plot(diabetes[,1:13], pch = 21)
```

```{r}
#  ===== Eksplorasi asumsi =====
plot(model,1)                # plot sisaan vs yduga
plot(model,2)                # qq-plot
plot(x = 1:dim(diabetes)[1],
     y = model$residuals,
     type = 'b', 
     ylab = "Residuals",
     xlab = "Observation")       # plot sisaan vs urutan
```
```{r}
# ===== Uji Asumsi Formal =====
# Asumsi GAUSS MARKOV
# 1 Nilai harapan sisaan sama dengan nol
t.test(model$residuals,
       mu = 0,
       conf.level = 0.95)
```
Asumsi terpenuhi karena p-value = 1

```{r}
# ASUMSI NORMALITAS SISAAN
# Menggunakan Shapiro Wilk Test
ks.test(model$residuals, "pnorm", mean=mean(model$residuals), sd=sd(model$residuals))
library(car)
shapiro.test(model$residuals)
```
Hipotesis
H0 : Residual berdistribusi normal
H1 : Residual tidak berdistribusi normal
Keputusan : Karena p-value (0.9514) > alpha (0.05), maka gagal tolak H0
Kesimpulan : Dengan tingkat keyakinan 95%, kita yakin bahwa residual berdistribusi normal.

```{r}
# Menggunakan Uji Jarque Bera
library("tseries")
residual=resid(model)
jarque.bera.test(residual)
```
Hipotesis
H0 : Residual berdistribusi normal
H1 : Residual tidak berdistribusi normal
Keputusan : Karena p-value (0.9287) > alpha (0.05), maka gagal tolak H0
Kesimpulan : Dengan tingkat keyakinan 95%, kita yakin bahwa residual berdistribusi normal.

```{r}
# UJI AUTOKORELASI
# Menggunakan Runs-test
library(randtests)
runs.test(model$residuals)
```
Hipotesis
H0 : Tidak ada auto korelasi dari galat
H1 : Ada auto korelasi dari galat
Keputusan : Karena p-value (0.3238) > alpha (0.05), maka gagal tolak H0
Kesimpulan : Dengan tingkat keyakinan 95%, kita yakin bahwa tidak ada auto korelasi pada galat.

```{r}
# Menggunakan Uji Durbin Watson
library(lmtest)
dwtest(model)
```
Hipotesis
H0 : Tidak ada auto korelasi dari galat
H1 : Ada auto korelasi dari galat
Keputusan : Karena p-value (0.1235) > alpha (0.05), maka gagal tolak H0
Kesimpulan : Dengan tingkat keyakinan 95%, kita yakin bahwa tidak ada auto korelasi pada galat.

```{r}
# UJI KEHOMOGENAN RAGAM (HOMOSKEDASTISITAS)
# Menggunakan Uji Breusch Pagan
bptest(model, data=diabetes)
```
Hipotesis
H0 : Ragam Homogen
H1 : Ragam tidak homogen
Keputusan : Karena p-value (0.185) > alpha (0.05) maka gagal tolak H0.
Kesimpulan : Dengan tingkat keyakinan 95%, kita yakin bahwa ragam homogen

```{r}
# UJI MULTIKOLINEARITAS
vif(model)
```
Semua variabel memiliki nilai VIF < 10 sehingga tidak mengindikasikan adanya multikolinieritas
```{r}
library(olsrr)
ols_vif_tol(model)
```
Semua variabel memiliki nilai toleransi lebih dari 0.1 dan VIF < 10 sehingga tidak mengindikasikan adanya multikolinieritas

```{r}
#UJI LINEARITAS
lmtest::resettest(model, power=2)
```
p-value = 0.13 > α(0,05)
Kesimpulan: model linier.

```{r}
library(olsrr)
ols_step_all_possible(model)
```

```{r}
###BEST SUBSET REGRESSION###
library(MASS)
#---Stepwise Regression Model----
step.model <- stepAIC(model, direction = "both", trace = F)
summary(step.model)

#---Backward Regression Model----
back.model <- stepAIC(model, direction = "backward", trace =  F)
summary(back.model)

#---Forward Regression Model----
fwd.model <- stepAIC(model, direction = "forward", trace = F)
summary(fwd.model)
```
Berdasarkan ketiga metode yang digunakan, dapat terlihat model dapat diperbarui dengan memakai x5,x8,x9,x10 saja. Model regresi dengan variabel baru memiliki Adj R-square lebih baik dibanding model regresi yang menggunakan semua variabel.

```{r}
# MODEL REGRESI BARU
diabetes2 <- read.table(header = T, text = "
y	x5	x8	x9	x10
1.04	74.54	84.82	15.32	2.7
1.75	68.43	83.91	16.18	4.23
1.34	54.86	87.72	16.49	4.05
1.5	36.23	85.56	18.4	3.46
2.01	47.09	82.65	22.61	7.15
1.98	37.89	86.12	25.02	3.47
1.4	48.29	84.78	23.53	7.02
1.87	61.44	87.9	22.56	10.92
1.45	50.69	88.66	22.65	8.24
1.55	38.57	84.27	24.77	8.2
1.24	52.62	91.6	16.68	7.23
2.19	58.55	85.7	19.54	15.1
1.66	57.24	89.88	21.57	15.72
1.71	42.06	84.64	23.95	9.65
3.47	46.17	74.11	27.99	9.68
2.25	61.17	89.23	25.2	5.84
2.76	39.25	84.68	24.5	7.07
1.95	56.39	84.93	21.45	4.14
2.3	75.2	82.51	20.47	2.99
1.96	66.32	79.72	22.15	3.68
2.51	73.13	85.17	17.76	4.26
1.72	69.52	82.92	19.65	3.26
1.24	51.42	87.57	15.12	3.77
1.86	46.69	84.89	20.42	7.89
3.44	48.16	77	26.92	11.49
1.28	18.46	88.81	16.51	22.69
0.99	28.22	92.71	16.07	16.06
1.08	33.91	92.08	15.72	25.21
0.75	12.68	92.53	16.48	9.9
2.68	35.41	80.88	24.57	4.81
2.57	29.62	70.54	31.93	3.92
2.29	55.73	74.61	29.17	7.49
3.4	70.53	80.74	30.76	18.09
2.82	47.35	81.04	29.73	16.15
3.83	57.74	69.19	32.13	8.91
4.22	63.05	67.97	29.81	6.27
3.48	46.35	72.91	28	12.23
1.91	46.13	81.79	26.68	3.32")
```

```{r}
# MODEL REGRESI
# Uji hipotesis simultan
model2<-lm(y ~ ., data = diabetes2)
anova(model2)
summary(model2)
```
```{r}
ri = rstandard(model2)
hii = hatvalues(model2)
Obs = c(1:38)
summ <- cbind.data.frame(Obs, hii, ri)
View(summ)
```

```{r}
#Eksploratif amatan berpengaruh (jarak cook)
plot(model2, 5)
#mendeteksi amatan berpengaruh
influence.measures(model2)
```

```{r}
# BOXPLOT
library(ggplot2)
ggplot(diabetes2, aes(y)) +
  geom_boxplot(fill = c("purple"),
               alpha = 0.3) +
  theme(legend.position = "none")
library(ggplot2)
ggplot(diabetes2, aes(x5)) +
  geom_boxplot(fill = c("lightblue"),
               alpha = 0.5) +
  theme(legend.position = "none")
library(ggplot2)
ggplot(diabetes2, aes(x8)) +
  geom_boxplot(fill = c("green"),
               alpha = 0.5) +
  theme(legend.position = "none")
library(ggplot2)
ggplot(diabetes2, aes(x9)) +
  geom_boxplot(fill = c("grey"),
               alpha = 0.5) +
  theme(legend.position = "none")
library(ggplot2)
ggplot(diabetes2, aes(x10)) +
  geom_boxplot(fill = c("cyan"),
               alpha = 0.5) +
  theme(legend.position = "none")
boxplot(diabetes2$y, diabetes2$x5, diabetes2$x8, diabetes2$x9, diabetes2$x10)
```
```{r}
M=data.matrix(diabetes2[, c('y','x5','x8','x9','x10')])

boxplot(M)
```
```{r}
# == Mendeteksi Pencilan dari Boxplot == #
nilai_outlier1 = boxplot.stats(diabetes2$x8)$out
nilai_outlier2 = boxplot.stats(diabetes2$x10)$out
nilai_outlier1
nilai_outlier2
```

```{r}
# == Matriks Korelasi untuk model terbaik == #
library(corrplot)
korelasi = cor(diabetes2)
corrplot(korelasi)
korelasi
```
```{r}
# == Scatter plot untuk model terbaik == #
plot(diabetes2[,1:5], pch = 21)
```

```{r}
#  ===== Eksplorasi asumsi =====
plot(model2,1)                # plot sisaan vs yduga
plot(model2,2)                # qq-plot
plot(x = 1:dim(diabetes2)[1],
     y = model2$residuals,
     type = 'b', 
     ylab = "Residuals",
     xlab = "Observation")       # plot sisaan vs urutan
```
```{r}
# ===== Uji Asumsi Formal =====
# Asumsi GAUSS MARKOV
# 1 Nilai harapan sisaan sama dengan nol
t.test(model2$residuals,
       mu = 0,
       conf.level = 0.95)
```
Asumsi terpenuhi karena p-value = 1

```{r}
# ASUMSI NORMALITAS SISAAN
# Menggunakan Shapiro Wilk Test
ks.test(model2$residuals, "pnorm", mean=mean(model2$residuals), sd=sd(model2$residuals))
library(car)
shapiro.test(model2$residuals)
```
Hipotesis
H0 : Residual berdistribusi normal
H1 : Residual tidak berdistribusi normal
Keputusan : Karena p-value (0.9063) > alpha (0.05), maka gagal tolak H0
Kesimpulan : Dengan tingkat keyakinan 95%, kita yakin bahwa residual berdistribusi normal.

```{r}
# Menggunakan Uji Jarque Bera
library("tseries")
residual=resid(model2)
jarque.bera.test(residual)
```
Hipotesis
H0 : Residual berdistribusi normal
H1 : Residual tidak berdistribusi normal
Keputusan : Karena p-value (0.9754) > alpha (0.05), maka gagal tolak H0
Kesimpulan : Dengan tingkat keyakinan 95%, kita yakin bahwa residual berdistribusi normal.

```{r}
# UJI AUTOKORELASI
# Menggunakan Uji Durbin Watson
library(lmtest)
dwtest(model2)
```
Hipotesis
H0 : Tidak ada auto korelasi dari galat
H1 : Ada auto korelasi dari galat
Keputusan : Karena p-value (0.2289) > alpha (0.05), maka gagal tolak H0
Kesimpulan : Dengan tingkat keyakinan 95%, kita yakin bahwa tidak ada auto korelasi pada galat.

```{r}
# UJI KEHOMOGENAN RAGAM (HOMOSKEDASTISITAS)
# Menggunakan Uji Breusch Pagan
bptest(model2, data=diabetes2)
```
Hipotesis
H0 : Ragam Homogen
H1 : Ragam tidak homogen
Keputusan : Karena p-value (0.1787) > alpha (0.05) maka gagal tolak H0.
Kesimpulan : Dengan tingkat keyakinan 95%, kita yakin bahwa ragam homogen

```{r}
# UJI MULTIKOLINEARITAS
vif(model2)
```
Semua variabel memiliki nilai VIF < 10 sehingga tidak mengindikasikan adanya multikolinieritas
```{r}
ols_vif_tol(model2)
```
Semua variabel memiliki nilai toleransi lebih dari 0.1 dan VIF < 10 sehingga tidak mengindikasikan adanya multikolinieritas

```{r}
#UJI LINEARITAS
lmtest::resettest(model2, power=2)
```
p-value = 0.537 > α(0,05)
Kesimpulan: model linier.

Kesimpulan: Model regresi memenuhi semua asumsi, dengan variabel bebas x5,x8,x9,x10 dan Adj R-squared = 0.7777
Bentuk Regresi: 6.031956 + (0.011735)x5 - (0.073690)x8 + (0.060262)x9 + (0.029051)x10

```{r}
# == Model Regresi Robust == #
library(robustbase)
res <- lmrob(y~x5+x8+x9+x10, data=diabetes2)
summary(res)
```
Kesimpulan: Model regresi robust dengan peubah bebas x5,x8,x9,x10 memiliki nilai Adj R-squared tertinggi, yaitu sebesar 0.797. Oleh karena itu diambil model regresi robust dengan bentuk regresi: 6.489381 + (0.011368)x5 - (0.078625)x8 + (0.059474)x9 + (0.028755)x10
